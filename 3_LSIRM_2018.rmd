---
title: "Introduction To R - LSIRM 2018 3"
author: "Simon Kiss"
date: '2018-07-04'
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=F, message=F, results='hide')

```
# Data Management

This is a good moment to introduce you to some basic data and code management principles that will hopefully make your life much easier.  The basic idea is to break up your code into manageable chunks and save each chunk in a separate script. 


By using the command `source()` you can execute R scripts linearly.  What this means is that you can put some parts of your workflow in separate (i.e. more manageable chunks) and then source them in the next file. This has the added advantage of making analyses that you've done once before, executable for other projects when you need code you've written now. 

In practice, what I usually do is end up having at least three separate working scripts. The first reads the data in and conducts any recodes, the second that conducts some analyses, and the third that does some gussying up producing nice looking plots and tables. In the second file, I source the first file, and in the third file, I source the first and second .R files and play with the plots. If I discover I need to change something (say, I need to change a variable to a dichotomous variable), then I can go back and either change the initial recode or add another one. 

#### Assignment 1
>1. Try sourcing in the file from yesterday.

```{r read-in}
source('https://raw.githubusercontent.com/sjkiss/LSIRM_2018/master/2_LSIRM_2018.r')


```


### Tidy data
`ggplot()` really starts to sing, however, when we combine it with some of the newest innovations in R, namely the`dplyr` and the `tidyr`package.  To introduce these, it is crucial to understand the difference between long and wide data.  

In long (tidy) data, each column is one variable and each row is one observation.   Currently our data very tidy, however, the difference between the two is sometimes blurry and can change depending on your purposes. Sometimes we want to *reshape* data from wide to long format.  This can get to be a pretty technical - even philosophical - distinction, and we won't go into it.

Here's a quote from Hadley Wickham that illustrates this: 

> A dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways. Every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes.

That said, sometimes it can be blurry and you might want to reshape data depending on the purpose. For example, you might be satisfied with two variables `home phone` and `work phone` in one context. But in another (e.g. fraud detection) you might want two different variables `phone type` and `phone_number`. 
#### Assignment 2
>1. How many variables are there in this data set? What are they?

```{r table1, results='markup'}

#print table1
table1

```

There are 4 variables. Superficially, the variables are named `country`, `year`, `cases` and `population`. However, a different way to conceptualize the data would be as follows. 

```{r show-long-data, results='markup'}
#Show table2
table2
```

Here, the 4 variables are different: `country`, `year`, `type` (i.e. type of count or group of people) and `count`. 

The reason that it is worth thinking about how you want your data to be shaped is that it can facilitate easy visualization and analysis.  

The `tidyr` package makes it remarkably easy to reshape data from long to wide and vice verse.  The key function is the `gather()` function. It takes the data frame you want to reshape (e.g. gather) as the first argument, then it takes two arguments, the defaults are `Variable` and `value`. Lastly, you can specify specifically which columns you want to `gather()`

To deal with the example above: 
```{r show-table1, results='markup'}
#Show table1
table1
#Show table2
table2
```

We want to fold the two variables `cases` and `population` into two new variables. We dont' want to touch the variables `country` and `year`

So it looks like this. 

```{r gather-table-1, results='markup'}

  #Gather the data frame, name new columns Variable, Value, do not touch country and year
gather(table1, Variable, Value, cases, population) 

```

Now let's turn to our data frame: 
```{r, show-wide-data, results='markup'}
#show first 6 rows of ces
head(ces)
vars
```

The variables `pers_ret` and `pers_fdpol` were both variables about a person's financial situation. The only difference was the first was about the person's financial situatino in general and the second was about whether the federal government had any impact on that. 

We might want to visualize the distribution of both responses in one plot.  But because they are stored in two separate variables, this would be *very* hard to do in base-R.  This is a problem that the tidyverse was developed to solve.  

One problem we face is that `pers_ret` and `pers_fdpol` are `labelled` variables.  Take a look. 

```{r examine-personal-federal}
#Show pers_ret
ces$pers_ret
#Show pers_fdpol
ces$pers_fdpol
```


Part of the problem stems from the fat that the value labels are not in a meaningful order, i.e. `1=Better`, but `2=Worse`, but `3=Stayed the same`.That is not our problem, that's a problem of the original data set.  It would be more intuitive to have the levels go from one extreme to the other.  

We coudl attack this from a number of ways. 

We could recode the underlying number to a factor level. This relies on turning the `labelled` variable into a `number` with the function `as.numeric()`.  

```{r sample-recode, results='markup'}
ces$personal<-Recode(as.numeric(ces$pers_ret),"1='Better' ; 2='Worse' ; 3='Same'", levels=c('Worse', 'Same' ,'Better'), as.factor=T)
#federal policies
ces$federal<-Recode(as.numeric(ces$pers_fdpol),"1='Better' ; 2='Worse' ; 3='Same'", levels=c('Worse', 'Same' ,'Better'), as.factor=T)

```

#### Assignment 3
> 1. Gather `personal` and `federal` into one variable called `Finances`. Store the new data frame as out.Check the names of `out` to be sure that it worked. Plot with a barplot the distribution of responses facetting now by the new variable Finances. 

```{r assignment-3-solution}
str(ces)
#Examine variables
ces$personal
ces$federal
```


```{r plot-finances}
#Store the results of the command in out. Note, this can be added at the end, once you know you have the command correct. 
# Start with the data frame

  #Gather, name the new variables, then select the variables to be gathered
out<-gather(ces, Finances, Value, personal, federal )

#names
names(out)
#

#plot
ggplot(out, aes(x=Value))+geom_bar()+facet_grid(~Finances)
```

# filter, selecting
The tidyverse is meant to accomplish a few things. One of these things is to improve the readability of R code. Base R can be quite messy. 

One of the key innovations in the `tidyverse()` is the use of this character `%>%`. This is a pipe that sends the results of one command to the command on the next line. Technically, this character only works when the `magritr` library is loaded, but this is always loaded automatically when you run `library(tidyverse)` so you almost never have to worry about it.  

Another big issue is consistency. The `tidyverse()` is built ona consistent set of design principles that make it easier to use. 

For example, the base R way to select a few variables is to use the `subset()` command with the `select` argument: 

```{r show-subset-select}
subset(ces, select=c('gender', 'ideology'))
```
The same command is used to subset *cases* , not just variables.

```{r, results='markup'}
#This selects only males
subset(ces, select='gender',gender=='M')
```

By contrast the tidyverse uses two separate commands for these two different functions: `filter()` and `select()`


```{r, tidyverse-filter, results='markup'}
filter(ces, gender=='M')
```

```{r, tidyverse-select, results='markup'}
select(ces, c(gender, ideology))
```


Then, add another command to select only ideology
```{r filter-men-select-ideology}
ces %>% 
  filter(gender=='M') %>% 
  select(gender, ideology) 
```

Now, we can even feed that into ggplot2 to draw a histogram of men's ideology scores. Note that because we are feeding the data frame line-by-line to the next function, there is no need to name the data frame in the ggplot2 command, we can just substitute it with a `.`

```{r}

#Start with a data frame
ces %>% 
  #Filter out men
  filter(gender=='M') %>% 
  #select the variable you want
  select(ideology) %>% 
  #Do something you want
  ggplot(., aes(x=ideology))+geom_bar()
```



#### Assignment 4
> 1. In the last plot that we made, there were missing values that were reported. We could filter the dataset to exclude those values.  

```{r assignment-4}
#check out
str(out)
#Start with out as a data frame
out %>% 
  #filter out missing values on the value label
  filter(is.na(Value)==F) %>% 
  #plot
  ggplot(., aes(Value))+geom_bar()+facet_grid(~Finances)

```

# Grouping and summarizing
## Calculating group means

One of the most common things that we do in the social sciences is to calculate group means. This is fundamental in experimental fields like psychology and common in fields that deal with survey research. 

The `tidyverse` makes it extremely easy. 

The central concepts that make it easy are `grouping` and `summarizing`.  Both have their own functions with those names: `group_by()` and `summarise()`.

Grouping a data frame prepares it for analysis based on the values of the grouping variable. 

Summarizing that data frame then performs some analysis on each group formed by the grouping variable. 

Here, we want 

```{r calculate-group-means}
#Take dataframe
ces %>% 
  #name the grouping variable
  group_by(gender) %>% 
  #Then summarize each group by calculating its mean
  summarize(
    mean(ideology, na.rm=T)
  )
```

You can store the results of the summarizing function in a new variable name. 

```{r calculate-group-means-avg}
#Take dataframe
ces %>% 
  #name the grouping variable
  group_by(gender) %>% 
  #Then summarize each group by calculating its mean
  summarize(
    avg=mean(ideology, na.rm=T)
  )
```

The other thing you can do is create multiple groups. Let's say we want to find the average ideology score by degree status and gender.

```{r average-ideology-degree}

ces %>% 
  #name the grouping variable
  group_by(gender, degree) %>% 
  #Then summarize each group by calculating its mean
  summarize(
    avg=mean(ideology, na.rm=T)
  )
```

Then we can plot them. 

#### Assignment 5
> 1. PLot the average ideology scores for gender and degree. Filter out missing values. 

```{r assignment-5-solution}

ces %>% 
  #name the grouping variable
  group_by(gender, degree) %>% 
  #Then summarize each group by calculating its mean
  summarize(
    avg=mean(ideology, na.rm=T)
  ) %>% 
  filter(is.na(gender)==F& is.na(degree)==F) %>% 
  ggplot(., aes(x=gender, y=avg, col=degree))+geom_point()

```

You can also create multiple variables. 

```{r show-standard-errors}
ces %>% 
  #name the grouping variable
  group_by(gender, degree) %>% 
  na.omit() %>% 
  #Then summarize each group by calculating its mean
  summarize(
    avg=mean(ideology),
    sd=sd(ideology),
  freq=n(), 
  se=sd/sqrt(freq)
  ) 
```


# Mutating and Summarizing 

# Group Means 

# Generalized Linear Models


